# Stage-2 training: Mask2Former Swin-L (COCO panoptic pre-trained)
# Pseudo-labels: k=100 overclustered CAUSE semantics + SPIdepth depth-guided instances
#
# Key design choices:
#   - Swin-L backbone frozen (BACKBONE_LR_MULTIPLIER=0.0)
#   - class_embed reinitialized for k=100 classes, trained at 10x base LR
#   - Hungarian matching replaces DropLoss (DROP_LOSS=False)
#   - Gradient clip 0.01 (Mask2Former default, stricter than CUPS 1.0)
#   - batch_size=2 + accumulate=8 = effective 16 (fits A6000 48GB)
#
# Usage:
#   python refs/cups/train.py \
#       --experiment_config_file refs/cups/configs/train_cityscapes_mask2former_swinl_k100.yaml \
#       --disable_wandb
DATA:
  CROP_RESOLUTION: (640, 1280)
  SCALE: 0.625
  DATASET: "cityscapes"
  IGNORE_UNKNOWN_THING_REGIONS: True
  THING_STUFF_THRESHOLD: 0.01
  ROOT: "datasets/cityscapes/"
  ROOT_VAL: "datasets/cityscapes/"
  ROOT_PSEUDO: "datasets/cityscapes/cups_pseudo_labels_k100/"
MODEL:
  BACKBONE_TYPE: "mask2former_swinl"
  INFERENCE_CONFIDENCE_THRESHOLD: 0.5
  MASK2FORMER:
    PRETRAINED: "facebook/mask2former-swin-large-coco-panoptic"
    NUM_QUERIES: 200
    BACKBONE_LR_MULTIPLIER: 0.0
    WEIGHT_DECAY: 0.05
    NO_OBJECT_WEIGHT: 0.1
    CLASS_EMBED_LR_MULTIPLIER: 10.0
AUGMENTATION:
  NUM_STEPS_STARTUP: 500
  COPY_PASTE: True
  MAX_NUM_PASTED_OBJECTS: 8
  RESOLUTIONS:
    - [384, 768]
    - [416, 832]
    - [448, 896]
    - [480, 960]
    - [512, 1024]
    - [544, 1088]
    - [576, 1152]
    - [640, 1280]
    - [672, 1344]
    - [704, 1408]
SYSTEM:
  ACCELERATOR: "gpu"
  NUM_GPUS: 1
  NUM_WORKERS: 4
  LOG_PATH: "experiments"
  RUN_NAME: "cups_mask2former_swinl_k100_stage2"
TRAINING:
  STEPS: 4000
  BATCH_SIZE: 2
  ACCUMULATE_GRAD_BATCHES: 8
  PRECISION: "bf16-mixed"
  OPTIMIZER: "adamw"
  ADAMW:
    LEARNING_RATE: 0.0001
    WEIGHT_DECAY: 0.05
  GRADIENT_CLIP_ALGORITHM: "norm"
  GRADIENT_CLIP_VAL: 0.01
  VAL_EVERY_N_STEPS: 200
  DROP_LOSS: False
  DROP_LOSS_IOU_THRESHOLD: 0.4
VALIDATION:
  CACHE_DEVICE: "cpu"
