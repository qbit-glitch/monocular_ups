# Stage-2 training: Mask2Former Swin-Tiny on RTX A6000 Pro (48GB)
# Pseudo-labels: k=100 overclustered CAUSE + CC instances
#
# Key settings:
#   - bf16-mixed precision (A6000 has full bf16 support)
#   - batch_size=4 + accumulate=4 = effective 16
#   - Swin-Tiny backbone frozen, class_embed at 10x LR
#
# Usage:
#   cd unsupervised-panoptic-segmentation
#   PYTHONPATH=refs/cups:$PYTHONPATH python refs/cups/train.py \
#       --experiment_config_file refs/cups/configs/train_cityscapes_mask2former_swint_k80_gpu.yaml \
#       --disable_wandb
DATA:
  CROP_RESOLUTION: (640, 1280)
  SCALE: 0.625
  DATASET: "cityscapes"
  IGNORE_UNKNOWN_THING_REGIONS: True
  THING_STUFF_THRESHOLD: 0.01
  ROOT: "datasets/cityscapes/"
  ROOT_VAL: "datasets/cityscapes/"
  ROOT_PSEUDO: "datasets/cityscapes/cups_pseudo_labels_k100/"
MODEL:
  BACKBONE_TYPE: "mask2former_swinl"
  INFERENCE_CONFIDENCE_THRESHOLD: 0.5
  MASK2FORMER:
    PRETRAINED: "facebook/mask2former-swin-tiny-coco-panoptic"
    NUM_QUERIES: 100
    BACKBONE_LR_MULTIPLIER: 0.0
    WEIGHT_DECAY: 0.05
    NO_OBJECT_WEIGHT: 0.1
    CLASS_EMBED_LR_MULTIPLIER: 10.0
AUGMENTATION:
  NUM_STEPS_STARTUP: 500
  COPY_PASTE: True
  MAX_NUM_PASTED_OBJECTS: 8
  RESOLUTIONS:
    - [384, 768]
    - [416, 832]
    - [448, 896]
    - [480, 960]
    - [512, 1024]
    - [544, 1088]
    - [576, 1152]
    - [640, 1280]
    - [672, 1344]
    - [704, 1408]
SYSTEM:
  ACCELERATOR: "gpu"
  NUM_GPUS: 1
  NUM_WORKERS: 4
  LOG_PATH: "experiments"
  RUN_NAME: "cups_mask2former_swint_k100_stage2"
TRAINING:
  STEPS: 4000
  BATCH_SIZE: 4
  ACCUMULATE_GRAD_BATCHES: 4
  PRECISION: "bf16-mixed"
  OPTIMIZER: "adamw"
  ADAMW:
    LEARNING_RATE: 0.0001
    WEIGHT_DECAY: 0.05
  GRADIENT_CLIP_ALGORITHM: "norm"
  GRADIENT_CLIP_VAL: 0.01
  VAL_EVERY_N_STEPS: 200
  DROP_LOSS: False
  DROP_LOSS_IOU_THRESHOLD: 0.4
VALIDATION:
  CACHE_DEVICE: "cpu"
